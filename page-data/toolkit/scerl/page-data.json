{
    "componentChunkName": "component---src-pages-toolkit-scerl-mdx",
    "path": "/toolkit/scerl/",
    "result": {"pageContext":{"frontmatter":{"title":"SCERL","description":"A Text-based Safety Benchmark for Reinforcement Learning Problems","url":"https://github.com/IBM/SCERL","tag":"DS","tags":["DS"],"weight":2},"relativePagePath":"/toolkit/scerl.mdx","titleType":"prepend","MdxNode":{"id":"948e7a8f-da92-52c8-b9b8-0903aa904217","children":[],"parent":"81011b8a-0708-5e68-8742-20b7271916ac","internal":{"content":"---\ntitle: SCERL\ndescription: A Text-based Safety Benchmark for Reinforcement Learning Problems\nurl: https://github.com/IBM/SCERL\ntag: \"DS\"\ntags: [\"DS\"]\nweight: 2\n---\n\n## Description\n\nThis repository contains the source code and data for our paper SCERL: A Text-based Safety Benchmark for Reinforcement Learning Problems. SCERL is a text-based environment for reinforcement learning agents that:\n\n- provides a framework for genereting safety problems representing key safety challenges such as negative side effect, scalable oversight and safe exploration\n- includes a pre-generated set of text-based games with safety constraints in order to spoor research in safe and text-based reinforcement learning (see dataset/safety_games).\n\n## Main Contributors\n\nLan Hoang, Shivam Ratnakar, Nicolas Galichet, Akifumi Wachi, Keerthiram Murugesan, Songtao Lu, Mattia Atzeni, Michael Katz, Subhajit Chaudhury\n","type":"Mdx","contentDigest":"2887a864f27822c9fe192880bf16a92a","owner":"gatsby-plugin-mdx","counter":141,"fieldOwners":{"source":"gatsby-plugin-mdx-source-name"}},"frontmatter":{"title":"SCERL","description":"A Text-based Safety Benchmark for Reinforcement Learning Problems","url":"https://github.com/IBM/SCERL","tag":"DS","tags":["DS"],"weight":2},"exports":{},"rawBody":"---\ntitle: SCERL\ndescription: A Text-based Safety Benchmark for Reinforcement Learning Problems\nurl: https://github.com/IBM/SCERL\ntag: \"DS\"\ntags: [\"DS\"]\nweight: 2\n---\n\n## Description\n\nThis repository contains the source code and data for our paper SCERL: A Text-based Safety Benchmark for Reinforcement Learning Problems. SCERL is a text-based environment for reinforcement learning agents that:\n\n- provides a framework for genereting safety problems representing key safety challenges such as negative side effect, scalable oversight and safe exploration\n- includes a pre-generated set of text-based games with safety constraints in order to spoor research in safe and text-based reinforcement learning (see dataset/safety_games).\n\n## Main Contributors\n\nLan Hoang, Shivam Ratnakar, Nicolas Galichet, Akifumi Wachi, Keerthiram Murugesan, Songtao Lu, Mattia Atzeni, Michael Katz, Subhajit Chaudhury\n","fileAbsolutePath":"/home/travis/build/IBM-Research-AI/neuro-symbolic-ai-toolkit-site/src/pages/toolkit/scerl.mdx","fields":{"source":"toolkit"},"__gatsby_resolved":{"fields":{"source":"toolkit"},"frontmatter":{"tags":["DS"],"weight":2},"slug":"scerl"}}}},
    "staticQueryHashes": ["1008643715","1364590287","137577622","1404468418","151170173","1794870524","2102389209","2746626797","3018647132","3037994772","3151510810","768070550"]}