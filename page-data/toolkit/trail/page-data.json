{
    "componentChunkName": "component---src-pages-toolkit-trail-mdx",
    "path": "/toolkit/trail/",
    "result": {"pageContext":{"frontmatter":{"title":"Trial Reasoner for AI that Learns","description":"A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving","url":"https://github.com/ibm/TRAIL","tag":"LwL","tags":["LwL"],"weight":10},"relativePagePath":"/toolkit/trail.mdx","titleType":"prepend","MdxNode":{"id":"50374e13-5cdc-584e-8f42-78d2d4f4ee3f","children":[],"parent":"c0dc4c96-f05f-5145-a82b-af2811a070c1","internal":{"content":"---\ntitle: Trial Reasoner for AI that Learns\ndescription: A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving\nurl: https://github.com/ibm/TRAIL\ntag: \"LwL\"\ntags: [\"LwL\"]\nweight: 10\n---\n\n## TRAIL: A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving\n\nAutomated theorem provers have traditionally relied on manually tuned heuristics to guide how they perform proof search. Deep reinforcement learning has been proposed as a way to obviate the need for such heuristics, however, its deployment in automated theorem proving remains a challenge. TRAIL (Trial Reasoner for AI that Learns) is a system that applies deep reinforcement learning to saturation-based theorem proving. TRAIL leverages (a) a novel neural representation of the state of a theorem prover and (b) a novel characterization of the inference selection process in terms of an attention-based action policy.\n\n## Main Contributors\n\nIbrahim Abdelaziz, Vernon Austel, Achille Fokoue.\n","type":"Mdx","contentDigest":"4c3fca41bdef76d8d2038172fadf8a70","owner":"gatsby-plugin-mdx","counter":147,"fieldOwners":{"source":"gatsby-plugin-mdx-source-name"}},"frontmatter":{"title":"Trial Reasoner for AI that Learns","description":"A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving","url":"https://github.com/ibm/TRAIL","tag":"LwL","tags":["LwL"],"weight":10},"exports":{},"rawBody":"---\ntitle: Trial Reasoner for AI that Learns\ndescription: A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving\nurl: https://github.com/ibm/TRAIL\ntag: \"LwL\"\ntags: [\"LwL\"]\nweight: 10\n---\n\n## TRAIL: A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving\n\nAutomated theorem provers have traditionally relied on manually tuned heuristics to guide how they perform proof search. Deep reinforcement learning has been proposed as a way to obviate the need for such heuristics, however, its deployment in automated theorem proving remains a challenge. TRAIL (Trial Reasoner for AI that Learns) is a system that applies deep reinforcement learning to saturation-based theorem proving. TRAIL leverages (a) a novel neural representation of the state of a theorem prover and (b) a novel characterization of the inference selection process in terms of an attention-based action policy.\n\n## Main Contributors\n\nIbrahim Abdelaziz, Vernon Austel, Achille Fokoue.\n","fileAbsolutePath":"/home/travis/build/IBM-Research-AI/neuro-symbolic-ai-toolkit-site/src/pages/toolkit/trail.mdx","fields":{"source":"toolkit"},"__gatsby_resolved":{"fields":{"source":"toolkit"},"frontmatter":{"tags":["LwL"],"weight":10},"slug":"trail"}}}},
    "staticQueryHashes": ["1008643715","1364590287","137577622","1404468418","151170173","1794870524","2102389209","2746626797","3018647132","3037994772","3151510810","768070550"]}